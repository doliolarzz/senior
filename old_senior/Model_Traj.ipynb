{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-604019163d98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnowcasting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrajGRU\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrajGRU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mexperiments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_params\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mencoder_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecaster_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/senior_implementations/experiments/net_params.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     96\u001b[0m     [\n\u001b[1;32m     97\u001b[0m         ConvLSTM(input_channel=8, num_filter=64, b_h_w=(batch_size, 96, 96),\n\u001b[0;32m---> 98\u001b[0;31m                  kernel_size=3, stride=1, padding=1),\n\u001b[0m\u001b[1;32m     99\u001b[0m         ConvLSTM(input_channel=192, num_filter=192, b_h_w=(batch_size, 32, 32),\n\u001b[1;32m    100\u001b[0m                  kernel_size=3, stride=1, padding=1),\n",
      "\u001b[0;32m~/senior_implementations/nowcasting/models/convLSTM.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_channel, num_filter, b_h_w, kernel_size, stride, padding)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Howerver, if you use declare an optimizer like Adam(model.parameters()),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# parameters will not be updated forever.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWci\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLOBAL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWcf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLOBAL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWco\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLOBAL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "from nowcasting.config import cfg\n",
    "from nowcasting.models.forecaster import Forecaster\n",
    "from nowcasting.models.encoder import Encoder\n",
    "from nowcasting.models.model import EF\n",
    "from torch.optim import lr_scheduler\n",
    "from nowcasting.models.loss import Weighted_mse_mae\n",
    "import os, shutil\n",
    "from nowcasting.models.trajGRU import TrajGRU\n",
    "from experiments.net_params import encoder_params, forecaster_params\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./rainy-nexrad-normed.npz')\n",
    "x_data = data['x_data']\n",
    "x_mask = data['x_mask']\n",
    "x_max = data['x_max']\n",
    "x_min = data['x_min']\n",
    "x = np.ma.MaskedArray(x_data, x_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1459, 1, 60, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = 0.0\n",
    "save_dir = os.path.join(cfg.GLOBAL.MODEL_SAVE_DIR, 'g')\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "model_save_dir = os.path.join(save_dir, 'models')\n",
    "log_dir = os.path.join(save_dir, 'logs')\n",
    "all_scalars_file_name = os.path.join(save_dir, \"all_scalars.json\")\n",
    "pkl_save_dir = os.path.join(save_dir, 'pkl')\n",
    "if os.path.exists(all_scalars_file_name):\n",
    "    os.remove(all_scalars_file_name)\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "if os.path.exists(model_save_dir):\n",
    "    shutil.rmtree(model_save_dir)\n",
    "os.mkdir(model_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(encoder_params[0], encoder_params[1]).to(cfg.GLOBAL.DEVICE)\n",
    "forecaster = Forecaster(forecaster_params[0], forecaster_params[1]).to(cfg.GLOBAL.DEVICE)\n",
    "encoder_forecaster = EF(encoder, forecaster).to(cfg.GLOBAL.DEVICE)\n",
    "\n",
    "LR_step_size = 20000\n",
    "gamma = 0.7\n",
    "max_iterations = 5000\n",
    "LR = 1e-4\n",
    "batch_size = cfg.GLOBAL.BATCH_SZIE\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(encoder_forecaster.parameters(), lr=LR)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=LR_step_size, gamma=gamma)\n",
    "\n",
    "t_end = 729\n",
    "t_each = 146\n",
    "eval_every = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [29:03<00:00,  2.87it/s]\n",
      " 51%|█████     | 2540/5000 [14:42<14:12,  2.89it/s]"
     ]
    }
   ],
   "source": [
    "train_loss = 0.0\n",
    "writer = SummaryWriter()\n",
    "all_itera = 1\n",
    "dataset = torch.from_numpy(x.astype(np.float32)).to(cfg.GLOBAL.DEVICE)\n",
    "for t_train in range(5):\n",
    "    x_train = dataset[:,:t_end]\n",
    "    x_val = dataset[:,t_end:t_end+t_each]\n",
    "    t_end += t_each\n",
    "    \n",
    "    for itera in tqdm(range(1, max_iterations+1)):\n",
    "        \n",
    "        idx = np.arange(x_train.shape[0])\n",
    "        np.random.shuffle(idx)\n",
    "        for b in range(int(np.ceil(x_train.shape[0] / batch_size))):\n",
    "            cur_idx = idx[b*batch_size:(b+1)*batch_size]\n",
    "            train_batch = x_train[:,cur_idx,:]\n",
    "            train_data = train_batch[:5, ...]\n",
    "            train_label = train_batch[5:6, ...]\n",
    "\n",
    "            encoder_forecaster.train()\n",
    "            optimizer.zero_grad()\n",
    "            output = encoder_forecaster(train_data)\n",
    "            loss = mse_loss(output, train_label)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_value_(encoder_forecaster.parameters(), clip_value=50.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            exp_lr_scheduler.step()\n",
    "\n",
    "        valid_loss = 0.0\n",
    "        valid_time = 0\n",
    "        with torch.no_grad():\n",
    "            encoder_forecaster.eval()\n",
    "            for b in range(int(np.ceil(x_val.shape[0]/batch_size))):\n",
    "                val_batch = x_val[:,b*batch_size: (b+1)*batch_size]\n",
    "                val_data = train_batch[:5, ...]\n",
    "                val_label = train_batch[5:6, ...]\n",
    "                output = encoder_forecaster(val_data)\n",
    "                loss = mse_loss(output, val_label)\n",
    "                valid_loss += loss.item()\n",
    "                valid_time += 1\n",
    "\n",
    "        writer.add_scalars(\"mse\", {\n",
    "            \"train\": train_loss/eval_every,\n",
    "            \"valid\": valid_loss/valid_time,\n",
    "        }, all_itera)\n",
    "        train_loss = 0.0\n",
    "\n",
    "        all_itera += 1\n",
    "\n",
    "    torch.save(encoder_forecaster.state_dict(), os.path.join(model_save_dir, 'traj_{}_{}.pth'.format(t_train,itera)))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
