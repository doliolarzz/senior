{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ConvGRU import ConvGRU\n",
    "from Encoder_Decoder import EF, Encoder, Forecaster\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm.notebook import tqdm\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchsummary import summary\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "from collections import OrderedDict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Tesla P100-PCIE-16GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./rainy-nexrad-normed.npz')\n",
    "x_data = data['x_data']\n",
    "x_mask = data['x_mask']\n",
    "x = np.ma.MaskedArray(x_data, x_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"files.pkl\", \"rb\") as f:\n",
    "    files = pickle.load(f)\n",
    "with open(\"dts.pkl\", \"rb\") as f:\n",
    "    dts = pickle.load(f)\n",
    "with open(\"lost_mark.pkl\", \"rb\") as f:\n",
    "    lost_mark = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_delta = np.vectorize(lambda x: x.seconds//60)(np.array(dts[1:]) - np.array(dts[:-1]))\n",
    "mark = np.argwhere(time_delta>15).reshape(-1) + 1\n",
    "mark = np.append(mark, len(files))\n",
    "mark = np.array(sorted(np.unique(mark.tolist() + lost_mark)))\n",
    "sliding_idx = np.arange(x.shape[0] - window_size + 1).astype(np.int)\n",
    "remove_idx = np.array([]).astype(np.int)\n",
    "for i in range(mark.shape[0]):\n",
    "    remove_idx = np.append(remove_idx, np.arange(window_size - 1) + mark[i] - window_size + 1)\n",
    "use_idx = np.setdiff1d(sliding_idx, remove_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4404"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(use_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvGRU (input_size, hidden_size, kernel_size, b_t_c_h_w)\n",
    "batch_size = 16\n",
    "encoder_params = [\n",
    "    [\n",
    "        OrderedDict({'conv1_leaky_1': [1, 8, 7, 5, 1]}),\n",
    "        OrderedDict({'conv2_leaky_1': [64, 192, 5, 3, 1]}),\n",
    "        OrderedDict({'conv3_leaky_1': [192, 192, 3, 2, 1]}),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        ConvGRU(input_channel=8, num_filter=64, b_h_w=(batch_size, 96, 96),\n",
    "                 kernel_size=3, stride=1, padding=1),\n",
    "        ConvGRU(input_channel=192, num_filter=192, b_h_w=(batch_size, 32, 32),\n",
    "                 kernel_size=3, stride=1, padding=1),\n",
    "        ConvGRU(input_channel=192, num_filter=192, b_h_w=(batch_size, 16, 16),\n",
    "                 kernel_size=3, stride=1, padding=1),\n",
    "    ]\n",
    "]\n",
    "decoder_params = [\n",
    "    [\n",
    "        OrderedDict({'deconv1_leaky_1': [192, 192, 4, 2, 1]}),\n",
    "        OrderedDict({'deconv2_leaky_1': [192, 64, 5, 3, 1]}),\n",
    "        OrderedDict({\n",
    "            'deconv3_leaky_1': [64, 8, 7, 5, 1],\n",
    "            'conv3_leaky_2': [8, 8, 3, 1, 1],\n",
    "            'conv3_3': [8, 1, 1, 1, 0]\n",
    "        }),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        ConvGRU(input_channel=192, num_filter=192, b_h_w=(batch_size, 16, 16),\n",
    "                 kernel_size=3, stride=1, padding=1),\n",
    "        ConvGRU(input_channel=192, num_filter=192, b_h_w=(batch_size, 32, 32),\n",
    "                 kernel_size=3, stride=1, padding=1),\n",
    "        ConvGRU(input_channel=64, num_filter=64, b_h_w=(batch_size, 96, 96),\n",
    "                 kernel_size=3, stride=1, padding=1),\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = Encoder(encoder_params[0], encoder_params[1]).to(device)\n",
    "# decoder = Forecaster(decoder_params[0], decoder_params[1]).to(device)\n",
    "# encoder_decoder = EF(encoder, decoder).to(device)\n",
    "# LR_step_size = 10\n",
    "# gamma = 0.8\n",
    "# max_iterations = 20\n",
    "# LR = 1e-3\n",
    "# mse_loss = torch.nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(encoder_decoder.parameters(), lr=LR)\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=LR_step_size, gamma=gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# summary(encoder_decoder, (window_size, 1, 480, 480), batch_size, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_dot(encoder_decoder(torch.randn(1, window_size, 1, 480, 480).cuda()),\n",
    "#          params=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_end = 4000\n",
    "t_each = 327\n",
    "eval_every = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsize = x_data.dtype.itemsize\n",
    "x_data_slided = np.lib.stride_tricks.as_strided(x_data, \n",
    "        (x_data.shape[0]-window_size+1,window_size, x_data.shape[1], x_data.shape[2]), \n",
    "        (x_data.shape[1]*x_data.shape[2]*dsize, x_data.shape[1]*x_data.shape[2]*dsize, x_data.shape[2]*dsize, dsize))\n",
    "x_data_slided = x_data_slided.swapaxes(0,1)[:,:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 4483, 1, 480, 480)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_slided.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsize = x_mask.dtype.itemsize\n",
    "x_mask_slided = np.lib.stride_tricks.as_strided(x_mask, \n",
    "        (x_mask.shape[0]-window_size+1,window_size, x_mask.shape[1], x_mask.shape[2]), \n",
    "        (x_mask.shape[1]*x_mask.shape[2]*dsize, x_mask.shape[1]*x_mask.shape[2]*dsize, x_mask.shape[2]*dsize, dsize))\n",
    "x_mask_slided = x_mask_slided.swapaxes(0,1)[:,:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = 0.0\n",
    "writer = SummaryWriter('./convGRU_tb', flush_secs=10)\n",
    "all_itera = 1\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dec59b65a5641369829183b4e07e61c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch: ', max=20, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173c61cfab1640a3a2e1c6ced616d5f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='batch: ', max=250, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e438ed67007045a8926aa64e6d941950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='batch: ', max=250, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc222fd479df4bb59c683d254108e167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='batch: ', max=250, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e504c05e85a1445b9fbc87b41bdfc80c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='batch: ', max=250, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-def67b23ef04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_value_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2202\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2203\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2204\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2205\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for t_train in range(3):\n",
    "    encoder = Encoder(encoder_params[0], encoder_params[1]).to(device)\n",
    "    decoder = Forecaster(decoder_params[0], decoder_params[1]).to(device)\n",
    "    encoder_decoder = EF(encoder, decoder).to(device)\n",
    "    LR_step_size = 10\n",
    "    gamma = 0.8\n",
    "    max_iterations = 20\n",
    "    LR = 1e-4\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(encoder_decoder.parameters(), lr=LR)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=LR_step_size, gamma=gamma)\n",
    "\n",
    "    x_train_idx = use_idx[:t_end]\n",
    "    x_val_idx = use_idx[t_end:t_end+t_each]\n",
    "    t_end += t_each\n",
    "    idx = np.arange(x_train_idx.shape[0])\n",
    "    for itera in tqdm(range(1, max_iterations+1), desc='epoch: '):\n",
    "        np.random.shuffle(idx)\n",
    "        for b in tqdm(range(int(np.floor(idx.shape[0] / batch_size))), desc='batch: '):\n",
    "            cur_idx = x_train_idx[idx[b*batch_size:min((b+1)*batch_size, idx.shape[0])]]\n",
    "            train_batch = torch.from_numpy(x_data_slided[:,cur_idx,:].astype(np.float32)).to(device)\n",
    "            train_data = train_batch[:6, ...]\n",
    "            train_label = train_batch[6:, ...]\n",
    "            encoder_decoder.train()\n",
    "            optimizer.zero_grad()\n",
    "            output = encoder_decoder(train_data)\n",
    "            loss = mse_loss(output, train_label)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_value_(encoder_decoder.parameters(), clip_value=50.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            exp_lr_scheduler.step()\n",
    "            del train_data\n",
    "            del train_label\n",
    "            del train_batch\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        valid_loss = 0.0\n",
    "        valid_time = 0\n",
    "        with torch.no_grad():\n",
    "            encoder_decoder.eval()\n",
    "            for bb in range(int(np.floor(x_val_idx.shape[0]/batch_size))):\n",
    "                val_batch = torch.from_numpy(x_data_slided[:,x_val_idx[bb*batch_size:min((bb+1)*batch_size, idx.shape[0])]].astype(np.float32)).to(device)\n",
    "                val_data = val_batch[:6, ...]\n",
    "                val_label = val_batch[6:, ...]\n",
    "                output = encoder_decoder(val_data)\n",
    "                loss = mse_loss(output, val_label)\n",
    "                valid_loss += loss.item()\n",
    "                valid_time += 1\n",
    "                del val_data\n",
    "                del val_label\n",
    "                del val_batch\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        writer.add_scalars(\"mse\", {\n",
    "            \"train\": train_loss/idx.shape[0],\n",
    "            \"valid\": valid_loss/x_val_idx.shape[0],\n",
    "        }, all_itera)\n",
    "        history.append([all_itera, train_loss/idx.shape[0], valid_loss/x_val_idx.shape[0]])\n",
    "        train_loss = 0.0\n",
    "\n",
    "        all_itera += 1\n",
    "    torch.save(encoder_decoder.state_dict(), os.path.join(model_save_dir, 'convGRU_{}_{}.pth'.format(t_train,all_itera)))\n",
    "writer.close()\n",
    "with open('convGRU_train.pickle', 'wb') as handle:\n",
    "    pickle.dump(history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
