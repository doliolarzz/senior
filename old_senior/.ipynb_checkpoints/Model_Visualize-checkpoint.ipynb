{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import torch\n",
    "from nowcasting.config import cfg\n",
    "from nowcasting.models.forecaster import Forecaster\n",
    "from nowcasting.models.encoder import Encoder\n",
    "from nowcasting.models.model import EF\n",
    "from torch.optim import lr_scheduler\n",
    "from nowcasting.models.loss import Weighted_mse_mae\n",
    "import os, shutil\n",
    "from experiments.net_params import convlstm_encoder_params, convlstm_forecaster_params\n",
    "from nowcasting.models.trajGRU import TrajGRU\n",
    "from experiments.net_params import encoder_params, forecaster_params\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./rainy-nexrad-normed.npz')\n",
    "x_data = data['x_data']\n",
    "x_mask = data['x_mask']\n",
    "x_max = data['x_max']\n",
    "x_min = data['x_min']\n",
    "x = np.ma.MaskedArray(x_data, x_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4494, 480, 480)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(convlstm_encoder_params[0], convlstm_encoder_params[1]).to(cfg.GLOBAL.DEVICE)\n",
    "forecaster = Forecaster(convlstm_forecaster_params[0], convlstm_forecaster_params[1]).to(cfg.GLOBAL.DEVICE)\n",
    "conv = EF(encoder, forecaster).to(cfg.GLOBAL.DEVICE)\n",
    "conv.load_state_dict(torch.load('../model_test/f/models/conv_0_20.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"files.pkl\", \"rb\") as f:\n",
    "    files = pickle.load(f)\n",
    "with open(\"dts.pkl\", \"rb\") as f:\n",
    "    dts = pickle.load(f)\n",
    "with open(\"lost_mark.pkl\", \"rb\") as f:\n",
    "    lost_mark = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_delta = np.vectorize(lambda x: x.seconds//60)(np.array(dts[1:]) - np.array(dts[:-1]))\n",
    "mark = np.argwhere(time_delta>15).reshape(-1) + 1\n",
    "mark = np.append(mark, len(files))\n",
    "mark = np.array(sorted(np.unique(mark.tolist() + lost_mark)))\n",
    "sliding_idx = np.arange(x.shape[0] - window_size + 1).astype(np.int)\n",
    "remove_idx = np.array([]).astype(np.int)\n",
    "for i in range(mark.shape[0]):\n",
    "    remove_idx = np.append(remove_idx, np.arange(window_size - 1) + mark[i] - window_size + 1)\n",
    "use_idx = np.setdiff1d(sliding_idx, remove_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4404"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(use_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.from_numpy(x_data[use_idx[4000:4308]].astype(np.float32)).to(cfg.GLOBAL.DEVICE)\n",
    "x_torch = dataset.unfold(0,window_size,1).permute(3,0,1,2)[:,:,None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 297, 1, 480, 480])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_torch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = x_torch[:6, ...]\n",
    "label = x_torch[-6:, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 285, 1, 480, 480)\n"
     ]
    }
   ],
   "source": [
    "bs=8\n",
    "with torch.no_grad():\n",
    "    image_conv = None\n",
    "    for i in range(int(np.ceil(x_torch.size(1)/bs))):\n",
    "        output_conv = data[:6,i*bs:min((i+1)*bs, x_torch.size(1))]\n",
    "        for j in range(3):\n",
    "            output_conv = conv(output_conv)\n",
    "        output_conv = output_conv.cpu().numpy()\n",
    "        if image_conv is not None:\n",
    "            image_conv = np.concatenate([image_conv, output_conv], axis=1)\n",
    "        else:\n",
    "            image_conv = output_conv\n",
    "image_conv = image_conv * (x_max - x_min) + x_min\n",
    "print(image_conv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 297, 1, 480, 480)\n"
     ]
    }
   ],
   "source": [
    "bs=8\n",
    "with torch.no_grad():\n",
    "    image_conv = None\n",
    "    for i in range(int(np.ceil(x_torch.size(1)/bs))):\n",
    "        output_conv = conv(data[:6,i*bs:min((i+1)*bs, x_torch.size(1))])\n",
    "        output_conv = output_conv.cpu().numpy()\n",
    "        if image_conv is not None:\n",
    "            image_conv = np.concatenate([image_conv, output_conv], axis=1)\n",
    "        else:\n",
    "            image_conv = output_conv\n",
    "image_conv = image_conv * (x_max - x_min) + x_min\n",
    "print(image_conv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 297, 1, 480, 480)\n"
     ]
    }
   ],
   "source": [
    "image_label = label.cpu().numpy() * (x_max - x_min) + x_min\n",
    "print(image_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 480\n",
    "h = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('./3hr_truth')\n",
    "mn = min(image_conv.min(), image_label.min())\n",
    "mx = max(image_conv.max(), image_label.max())\n",
    "for i in range(image_label.shape[1]):\n",
    "    x = image_label[-1,i,0]\n",
    "    y = np.array(((x - mn) / (mx - mn)) * 255,dtype=np.uint8)\n",
    "    f = cv2.cvtColor(y, cv2.COLOR_GRAY2RGB)\n",
    "    cv2.imwrite('./3hr_truth/3hr_truth_'+str(i).zfill(3)+'.png', f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = cv2.VideoWriter('compare_1hr.mp4',cv2.VideoWriter_fourcc(*'MP4V'), 10, (w*2+3*3,h+3*2))\n",
    "mn = min(image_conv.min(), image_label.min())\n",
    "mx = max(image_conv.max(), image_label.max())\n",
    "for i in range(image_label.shape[1]):\n",
    "    left = np.ones((h,3)) * mn\n",
    "    f = np.concatenate([left,image_conv[-1,i,0],left,image_label[-1,i,0],left], axis=1)\n",
    "    f = cv2.cvtColor(np.array((f - mn) / (mx - mn)*255,dtype=np.uint8), cv2.COLOR_GRAY2RGB)\n",
    "    top = np.zeros((3,w*2+3*3,3),dtype=np.uint8)\n",
    "    f = np.concatenate([top,f,top], axis=0)\n",
    "    out.write(f)\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = cv2.VideoWriter('compare_3hr.mp4',cv2.VideoWriter_fourcc(*'MP4V'), 10, (w*2+3*3,h+3*2))\n",
    "mn = min(image_conv.min(), image_label.min())\n",
    "mx = max(image_conv.max(), image_label.max())\n",
    "for i in range(image_label.shape[1]):\n",
    "    left = np.ones((h,3)) * mn\n",
    "    f = np.concatenate([left,image_conv[-1,i,0],left,image_label[-1,i,0],left], axis=1)\n",
    "    f = cv2.cvtColor(np.array((f - mn) / (mx - mn)*255,dtype=np.uint8), cv2.COLOR_GRAY2RGB)\n",
    "    top = np.zeros((3,w*2+3*3,3),dtype=np.uint8)\n",
    "    f = np.concatenate([top,f,top], axis=0)\n",
    "    out.write(f)\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = cv2.VideoWriter('all_model.mp4',cv2.VideoWriter_fourcc(*'MP4V'), 10, (w*4+50*5,h))\n",
    "border = np.ones((h,50,3),dtype=np.uint8) * 255\n",
    "for i in range(1, image_label.shape[0]):\n",
    "    label = cv2.cvtColor(cv2.resize(np.array(image_label[i] * 255,dtype=np.uint8).T, dsize=(w, h), interpolation=cv2.INTER_CUBIC), cv2.COLOR_GRAY2RGB)\n",
    "    pred_conv = cv2.cvtColor(cv2.resize(np.array(image_conv[i] * 255,dtype=np.uint8).T, dsize=(w, h), interpolation=cv2.INTER_CUBIC), cv2.COLOR_GRAY2RGB)\n",
    "    pred_traj = cv2.cvtColor(cv2.resize(np.array(image_traj[i] * 255,dtype=np.uint8).T, dsize=(w, h), interpolation=cv2.INTER_CUBIC), cv2.COLOR_GRAY2RGB)\n",
    "    pred_t1 = cv2.cvtColor(cv2.resize(np.array(image_label[i - 1] * 255,dtype=np.uint8).T, dsize=(w, h), interpolation=cv2.INTER_CUBIC), cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    out.write(255 - np.concatenate([border,label,border,pred_t1,border,pred_conv,border,pred_traj,border], axis=1))\n",
    "    \n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(x,y):\n",
    "    return np.sqrt(np.mean(np.square(x-y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_rain(x,y):\n",
    "    mask = y.reshape(-1)\n",
    "    mask = mask>thres\n",
    "    return np.sqrt(np.mean(np.square(x.reshape(-1)[mask]-y.reshape(-1)[mask])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_not_rain(x,y):\n",
    "    mask = y.reshape(-1)\n",
    "    mask = mask<thres\n",
    "    return np.sqrt(np.mean(np.square(x.reshape(-1)[mask]-y.reshape(-1)[mask])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csi(x,y):\n",
    "    xx = (x.reshape(-1) > thres).astype(np.int) * 2\n",
    "    yy = (y.reshape(-1) > thres).astype(np.int)\n",
    "    res = xx+yy\n",
    "    csi = np.sum(res==3) / (np.sum(res==3) + np.sum(res==1) + np.sum(res==2))\n",
    "    return csi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.977473"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(image_conv[-1], image_label[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.546831"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_rain(image_conv[-1], image_label[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.609939"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_not_rain(image_conv[-1], image_label[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.056461245440165286"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csi(image_conv[-1], image_label[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtr(dBZ):\n",
    "    return ((10**(dBZ/10))/200)**(5/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6527108"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(dtr(image_conv[-1]), dtr(image_label[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.684595"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_rain(dtr(image_conv[-1]), dtr(image_label[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05471131"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_not_rain(dtr(image_conv[-1]), dtr(image_label[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_end = 729\n",
    "t_each = 146\n",
    "t1_train_rmse = []\n",
    "conv_train_rmse = []\n",
    "traj_train_rmse = []\n",
    "t1_val_rmse = []\n",
    "conv_val_rmse = []\n",
    "traj_val_rmse = []\n",
    "for t_train in range(5):\n",
    "    x_train = x[:,:t_end]\n",
    "    x_val = x[:,t_end:t_end+t_each]\n",
    "    t_end += t_each\n",
    "    \n",
    "    x_torch_train = torch.from_numpy(x_train.astype(np.float32)).to(cfg.GLOBAL.DEVICE)\n",
    "    train_data = x_torch_train[:5, ...]\n",
    "    train_label = x_torch_train[5:6, ...].cpu().numpy()\n",
    "    \n",
    "    x_torch_val = torch.from_numpy(x_val.astype(np.float32)).to(cfg.GLOBAL.DEVICE)\n",
    "    val_data = x_torch_val[:5, ...]\n",
    "    val_label = x_torch_val[5:6, ...].cpu().numpy()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        train_traj = traj(train_data)\n",
    "    train_traj = train_traj.cpu().numpy()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        train_conv = conv(train_data)\n",
    "    train_conv = train_conv.cpu().numpy()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_traj = traj(val_data)\n",
    "    val_traj = val_traj.cpu().numpy()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_conv = conv(val_data)\n",
    "    val_conv = val_conv.cpu().numpy()\n",
    "    \n",
    "    t1_train_rmse.append(rmse(train_label[:,:-1], train_label[:,1:]))\n",
    "    conv_train_rmse.append(rmse(train_conv, train_label))\n",
    "    traj_train_rmse.append(rmse(train_traj, train_label))\n",
    "    t1_val_rmse.append(rmse(val_label[:,:-1], val_label[:,1:]))\n",
    "    conv_val_rmse.append(rmse(val_conv, val_label))\n",
    "    traj_val_rmse.append(rmse(val_traj, val_label))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00023013682, 0.00023665791, 0.00025148623, 0.00025377452, 0.00024126697]\n",
      "[0.00057227106, 0.0005798239, 0.00059455057, 0.00059644185, 0.00056816125]\n",
      "[0.0005609737, 0.0005636566, 0.0005862547, 0.0005862842, 0.00055647606]\n",
      "[0.00026763562, 0.0003275521, 0.00026833592, 9.369576e-05, 0.00016235112]\n",
      "[0.0006161524, 0.0006761207, 0.0006095043, 0.00024402342, 0.00039725448]\n",
      "[0.0005768662, 0.0007067046, 0.00058649, 0.00019336567, 0.0004099274]\n"
     ]
    }
   ],
   "source": [
    "print(t1_train_rmse)\n",
    "print(conv_train_rmse)\n",
    "print(traj_train_rmse)\n",
    "print(t1_val_rmse)\n",
    "print(conv_val_rmse)\n",
    "print(traj_val_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000225227, 0.0002308476, 0.0002459908, 0.00024819077, 0.00023555584]\n",
      "[0.0005405624, 0.0005410925, 0.0005606859, 0.0005631597, 0.0005365473]\n",
      "[0.0005112838, 0.00051146996, 0.00053044566, 0.0005357328, 0.00050764246]\n",
      "[0.00025787603, 0.0003231838, 0.00026215983, 8.18461e-05, 0.00015611586]\n",
      "[0.0005437319, 0.0006661426, 0.00058016414, 0.00023228738, 0.0003940223]\n",
      "[0.0005123988, 0.00063234754, 0.0005713402, 0.00015307272, 0.00037681145]\n"
     ]
    }
   ],
   "source": [
    "print(t1_train_rmse)\n",
    "print(conv_train_rmse)\n",
    "print(traj_train_rmse)\n",
    "print(t1_val_rmse)\n",
    "print(conv_val_rmse)\n",
    "print(traj_val_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
